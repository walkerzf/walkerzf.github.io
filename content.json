{"meta":{"title":"Zat's Blog","subtitle":"Zat 的自留地","description":"Have fun！","author":"Zhou Fang","url":"https://walkerzf.github.io","root":"/"},"pages":[{"title":"1","date":"2019-12-23T07:07:04.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"1/index.html","permalink":"https://walkerzf.github.io/1/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2020-11-22T06:41:23.252Z","updated":"2020-11-22T06:41:23.252Z","comments":false,"path":"/404.html","permalink":"https://walkerzf.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2020-11-22T06:41:23.252Z","updated":"2020-11-22T06:41:23.252Z","comments":false,"path":"about/index.html","permalink":"https://walkerzf.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2020-11-22T06:41:23.252Z","updated":"2020-11-22T06:41:23.252Z","comments":false,"path":"books/index.html","permalink":"https://walkerzf.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-11-22T06:41:23.252Z","updated":"2020-11-22T06:41:23.252Z","comments":false,"path":"categories/index.html","permalink":"https://walkerzf.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-11-22T06:41:23.252Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"links/index.html","permalink":"https://walkerzf.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-11-22T06:41:23.252Z","updated":"2020-11-22T06:41:23.252Z","comments":false,"path":"repository/index.html","permalink":"https://walkerzf.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-11-22T06:41:23.252Z","updated":"2020-11-22T06:41:23.252Z","comments":false,"path":"tags/index.html","permalink":"https://walkerzf.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"6.S081 FS Lab","slug":"FSLab","date":"2020-11-20T03:10:00.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/11/20/FSLab/","link":"","permalink":"https://walkerzf.github.io/2020/11/20/FSLab/","excerpt":"","text":"FS LabIn this lab you will add large files and symbolic links to the xv6 file system. In the first part , you will make the max size of a file in xv6 much bigger through sacrifice a direct block and adding a doubly-indirect block. In the second part , you will add symbolic link to the file in xv6 .Symbolic links resembles hard links, but hard links are restricted to pointing to file on the same disk, while symbolic links can cross disk devices. This is a good exercise to know about the pathname lookup in xv6 Part 1 Large filesThe first 11 elements of ip-&gt;addrs[] should be direct blocks; the 12th should be a singly-indirect block (just like the current one); the 13th should be your new doubly-indirect block. You are done with this exercise when bigfile writes 65803 blocks . 1234567#define NDIRECT 11#define DDIRECT 12#define NINDIRECT (BSIZE / sizeof(uint))struct inode &#123; //...// uint addrs[NDIRECT+1+1];&#125;; bmap function need to handle the doubly-indirect block 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768 uintbmap(struct inode *ip, uint bn)&#123; uint addr, *a; struct buf *bp; if (bn &lt; NDIRECT) &#123; if ((addr = ip-&gt;addrs[bn]) == 0) ip-&gt;addrs[bn] = addr = balloc(ip-&gt;dev); return addr; &#125; bn -= NDIRECT; if (bn &lt; NINDIRECT) &#123; // Load singly-indirect block, allocating if necessary. if ((addr = ip-&gt;addrs[NDIRECT]) == 0) ip-&gt;addrs[NDIRECT] = addr = balloc(ip-&gt;dev); bp = bread(ip-&gt;dev, addr); a = (uint *)bp-&gt;data; if ((addr = a[bn]) == 0) &#123; a[bn] = addr = balloc(ip-&gt;dev); log_write(bp); &#125; brelse(bp); return addr; &#125; // Load doubly-indirect block, allocating if necessary. bn -= NINDIRECT; //allocate if ((addr = ip-&gt;addrs[DDIRECT]) == 0) &#123; ip-&gt;addrs[DDIRECT] = addr = balloc(ip-&gt;dev); &#125; bp = bread(ip-&gt;dev, addr); a = (uint *)bp-&gt;data; //doubly-indirect block ,we need to allocate on the block int index = bn / NINDIRECT; for (int i = 0; i &lt;= index; i++) &#123; if ((addr = a[i]) == 0) &#123; a[i] = addr = balloc(ip-&gt;dev); //log write must be in the loop //because when we read we have not the fs syscall log_write(bp); &#125; &#125; brelse(bp); //read the exacyly indirect block , and allocate a block and write bn -= NINDIRECT * index; bp = bread(ip-&gt;dev, addr); a = (uint *)bp-&gt;data; if ((addr = a[bn]) == 0) &#123; a[bn] = addr = balloc(ip-&gt;dev); log_write(bp); &#125; brelse(bp); return addr; panic(\"bmap: out of range\");&#125; Make sure that struct inode and struct dinode have the same number of elements in their addrs[] arrays. We need to fix the struct dinode in the same way. itrunc function need to erase the content on the all block belonging to the inode or file 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// Truncate inode (discard contents).// Caller must hold ip-&gt;lock.void itrunc(struct inode *ip)&#123; int i, j; struct buf *bp; uint *a; for (i = 0; i &lt; NDIRECT; i++) &#123; if (ip-&gt;addrs[i]) &#123; bfree(ip-&gt;dev, ip-&gt;addrs[i]); ip-&gt;addrs[i] = 0; &#125; &#125; if (ip-&gt;addrs[NDIRECT]) &#123; bp = bread(ip-&gt;dev, ip-&gt;addrs[NDIRECT]); a = (uint *)bp-&gt;data; for (j = 0; j &lt; NINDIRECT; j++) &#123; if (a[j]) bfree(ip-&gt;dev, a[j]); &#125; brelse(bp); bfree(ip-&gt;dev, ip-&gt;addrs[NDIRECT]); ip-&gt;addrs[NDIRECT] = 0; &#125; if (ip-&gt;addrs[DDIRECT]) &#123; bp = bread(ip-&gt;dev, ip-&gt;addrs[DDIRECT]); a = (uint *)bp-&gt;data; struct buf *b; uint * ba; for (i = 0; i &lt; NINDIRECT; i++) &#123; if (a[i]) &#123; b = bread(ip-&gt;dev, a[i]); ba = (uint *)b-&gt;data; for (j = 0; j &lt; NINDIRECT; j++)&#123; if(ba[j]) bfree(ip-&gt;dev,ba[j]); &#125; brelse(b); bfree(ip-&gt;dev,a[i]); a[i] = 0; &#125; &#125; brelse(bp); bfree(ip-&gt;dev, ip-&gt;addrs[DDIRECT]); ip-&gt;addrs[DDIRECT] = 0; &#125; ip-&gt;size = 0; iupdate(ip);&#125; Part 2 Symbolic linksIn this part of lab , we need to add a system call into xv6 , which is symbolic links i.e. soft link . The symbolic links wants we to creates a new file which type is still FD_INODE, but the inode&#39;s type is T_SYMBOLIC , so we in the system call we need to allocate a new inode ,and allocate a new block for the first direct block .and write the length of the path and the path string in the block. Because the size of the length must a four-byte variable ,which is convenient for the read data from the block. 12345678910111213141516171819202122232425// labfs symbolic system calluint64sys_symlink(void)&#123; char target[MAXPATH], path[MAXPATH]; // struct inode *dp; struct inode *ip; //struct buf * b; //char * c; if (argstr(0, target, MAXPATH) &lt; 0 || argstr(1, path, MAXPATH) &lt; 0) return -1; begin_op(); //create will have the lock for the inode ip if((ip = create(path,T_SYMLINK,0,0))==0)&#123; end_op(); return -1; &#125; int len = strlen(target); writei(ip,0,(uint64)&amp;len,0,sizeof(len)); writei(ip,0,(uint64)target,sizeof(len),len+1); iunlockput(ip); end_op(); return 0;&#125; In sys_open system call , we need to fix the function to handle the inode&#39;s type is T_SYMBOLIC. And we should return false when we in a circle! 1234567891011121314151617181920int depth = 0,len ; char next[MAXPATH+1]; if(!(omode&amp;O_NOFOLLOW))&#123; for( ; depth&lt;10 &amp;&amp; ip-&gt;type ==T_SYMLINK ;depth++)&#123; readi(ip,0,(uint64)&amp;len,0,sizeof(len)); readi(ip,0,(uint64)next,sizeof(len),len); next[len]= 0; iunlockput(ip); if((ip=namei(next))==0)&#123; end_op(); return -1; &#125; ilock(ip); &#125; &#125; if(depth&gt;=10)&#123; iunlockput(ip); end_op(); return -1; &#125; LinkLink to Lab Page","categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"}]},{"title":"6.S081 FS Lab","slug":"Lock","date":"2020-11-19T07:20:00.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/11/19/Lock/","link":"","permalink":"https://walkerzf.github.io/2020/11/19/Lock/","excerpt":"","text":"Lock LabIn this lab you’ll gain experience in re-designing code to increase parallelism. A common symptom of poor parallelism on multi-core machines is high lock contention. Improving parallelism often involves changing both data structures and locking strategies in order to reduce contention. You’ll do this for the xv6 memory allocator and block cache. Memory allocatorIt is straightforward to assign each lock to each CPU ‘s freelist. The basic idea is to maintain a free list per CPU, each list with its own lock. Let freerange give all free memory to the CPU running freerange. The function cpuid returns the current core number, but it’s only safe to call it and use its result when interrupts are turned off. You should use push_off() and pop_off() to turn interrupts off and on. Redesign structkmem[NCPU] . 12345struct&#123; struct spinlock lock; struct run *freelist;&#125; kmem[NCPU]; Assign all free page to the CPU which calls the freerange. 123456789101112131415161718void freerange(void *pa_start, void *pa_end)&#123; push_off(); int id = cpuid(); acquire(&amp;kmem[id].lock); char *p; p = (char *)PGROUNDUP((uint64)pa_start); for (; p + PGSIZE &lt;= (char *)pa_end; p += PGSIZE)&#123; memset(p, 1, PGSIZE); struct run *r = (struct run *)p; r-&gt;next = kmem[id].freelist; kmem[id].freelist = r; &#125; release(&amp;kmem[id].lock); pop_off();&#125; Kfree and Kalloc will relate to the which CPU calls the function. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859void kfree(void *pa)&#123; struct run *r; if (((uint64)pa % PGSIZE) != 0 || (char *)pa &lt; end || (uint64)pa &gt;= PHYSTOP) panic(\"kfree\"); // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); r = (struct run *)pa; push_off(); int id = cpuid(); acquire(&amp;kmem[id].lock); r-&gt;next = kmem[id].freelist; kmem[id].freelist = r; pop_off(); release(&amp;kmem[id].lock); &#125;void *kalloc(void)&#123; struct run *r; push_off(); int id = cpuid(); acquire(&amp;kmem[id].lock); r = kmem[id].freelist; if (r) kmem[id].freelist = r-&gt;next; else &#123; for (int i = 0; i &lt; NCPU; i++) &#123; if (i == id) continue; acquire(&amp;kmem[i].lock); r = kmem[i].freelist; if (r) &#123; //remember to release kmem[i].freelist = r-&gt;next; release(&amp;kmem[i].lock); break; &#125;else&#123; //remember to release release(&amp;kmem[i].lock); &#125; &#125; &#125; release(&amp;kmem[id].lock); pop_off(); if (r) memset((char *)r, 5, PGSIZE); // fill with junk return (void *)r;&#125; Buffer cacheThis is similar to the Memory allocator , but we can not assign a bucket for each CPU , because these buffers are shared among each CPU or each Process. According to the hint , we remove the doubly-linked list , add two filed used (means the buffer is inuse or free) and timestamp to recycle a buffer. Struct BUF 12345678910111213struct buf &#123; int valid; // has data been read from disk? int disk; // does disk \"own\" buf? uint dev; uint blockno; struct sleeplock lock; uint refcnt; struct buf *prev; // LRU cache list struct buf *next; uchar data[BSIZE]; int used; uint timestamp;&#125;; bcache Bucket . helper lock helps the serialize eviction in Bget. 1234567#define NBUCKET 13struct spinlock helperlock;struct&#123; struct spinlock lock; struct buf buf[NBUF];&#125; bcache[NBUCKET]; Bget function 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697static struct buf *bget(uint dev, uint blockno)&#123; acquire(&amp;helperlock); struct buf *b; int id = blockno % NBUCKET; acquire(&amp;bcache[id].lock); // Is the block already cached? for (int i = 0; i &lt; NBUF; i++) &#123; b = &amp;bcache[id].buf[i]; if (b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno &amp;&amp; b-&gt;used) &#123; b-&gt;refcnt++; b-&gt;timestamp = ticks; release(&amp;bcache[id].lock); // pop_off(); release(&amp;helperlock); acquiresleep(&amp;b-&gt;lock); return b; &#125; &#125; // Not cached. // Recycle the least recently used (LRU) unused buffer. //what we need to do is to find a buffer index in index bucket //and recycle one buf whose timestamp is samllest and refcnt == 0 and active.! struct buf *dst = 0, *src = 0; uint time = 0x7fffffff; for (int i = 0; i &lt; NBUF; i++) &#123; if (bcache[id].buf[i].used == 0) &#123; dst = &amp;bcache[id].buf[i]; break; &#125; &#125; int pre = -1; //search a smallest timestamp for (int i = 0; i &lt; NBUCKET; i++) &#123; if (i != id) &#123; acquire(&amp;bcache[i].lock); &#125; int flag = 0; for (int j = 0; j &lt; NBUF; j++) &#123; b = &amp;bcache[i].buf[j]; if (b-&gt;used == 1 &amp;&amp; b-&gt;refcnt == 0 &amp;&amp; b-&gt;timestamp &lt; time) &#123; time = b-&gt;timestamp; src = b; flag = 1; &#125; &#125; if (flag) &#123; if (pre == -1) pre = i; else &#123; if (pre != id) release(&amp;bcache[pre].lock); pre = i; &#125; &#125; else if (i != id) &#123; release(&amp;bcache[i].lock); &#125; &#125; if (src == 0) panic(\"No buffer!\\n\"); //get the dst and src //implement replace if (dst == 0) &#123; dst = src; &#125; src-&gt;used = 0; dst-&gt;used = 1; dst-&gt;dev = dev; dst-&gt;blockno = blockno; dst-&gt;used = 1; dst-&gt;valid = 0; dst-&gt;refcnt = 1; release(&amp;bcache[id].lock); if(pre!=id) release(&amp;bcache[pre].lock); release(&amp;helperlock); acquiresleep(&amp;dst-&gt;lock); return dst;&#125; brelse bpin bunpin function 12345678910111213141516171819202122232425262728293031323334353637383940414243int findbucket(struct buf *b)&#123; for (int i = 0; i &lt; NBUCKET; i++) &#123; if (b &gt;= bcache[i].buf &amp;&amp; b &lt;= (bcache[i].buf + NBUF)) &#123; return i; &#125; &#125; panic(\"findbucket\");&#125;// Release a locked buffer.// Move to the head of the most-recently-used list.// we have the structure in the bucket , no need to move the buffer!void brelse(struct buf *b)&#123; if (!holdingsleep(&amp;b-&gt;lock)) panic(\"brelse\"); releasesleep(&amp;b-&gt;lock); int id = findbucket(b); acquire(&amp;bcache[id].lock); b-&gt;refcnt--; release(&amp;bcache[id].lock);&#125;void bpin(struct buf *b)&#123; int id = findbucket(b); acquire(&amp;bcache[id].lock); b-&gt;refcnt++; release(&amp;bcache[id].lock);&#125;void bunpin(struct buf *b)&#123; int id = findbucket(b); acquire(&amp;bcache[id].lock); b-&gt;refcnt--; release(&amp;bcache[id].lock);&#125; LinkLink to Lock Lab Page","categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"}]},{"title":"6.S081 Multithreading Lab","slug":"Multithreading","date":"2020-11-17T06:10:00.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/11/17/Multithreading/","link":"","permalink":"https://walkerzf.github.io/2020/11/17/Multithreading/","excerpt":"","text":"MultithreadingLabhis lab will familiarize you with multithreading. You will implement switching between threads in a user-level threads package, use multiple threads to speed up a program, and implement a barrier. Uthread: switching between threadsThe Thread 0 is the main function , which will not be scheduled again after scheduled out . Similar to the sched and schedule function , in uthread.c ,the ra and sp and other registers will be store and restore other thread’s registers in thread_schedule function (which is coded by asm ),so once the creation of the thread , the ra will be corresponding function , sp will the top of their own stack . Once every thread is created, thread_schedule, the three thread will continue to switching! In thread_schedule ,store and restore! 1234567891011121314151617181920212223242526272829303132thread_switch: &#x2F;* YOUR CODE HERE *&#x2F; sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret &#x2F;* return to ra *&#x2F; 1thread_switch((uint64)t,(uint64)current_thread); Creation of thread 12345678910111213void thread_create(void (*func)())&#123; struct thread *t; for (t = all_thread; t &lt; all_thread + MAX_THREAD; t++) &#123; if (t-&gt;state == FREE) break; &#125; t-&gt;state = RUNNABLE; // YOUR CODE HERE t-&gt;ra = (uint64)func; t-&gt;sp = (uint64)(t-&gt;stack+STACK_SIZE);&#125; This is different from the thread switching in the kernel . In this case ,we switch between different threads directly. In kernel , we switch to the CPU’s schedule thread ,and pick a thread to switch to. Using threadsWe will create a lock for each bucket! 1234567pthread_mutex_t lock[NBUCKET]; struct entry &#123; int key; int value; struct entry *next;&#125;;struct entry *table[NBUCKET]; For concurrent put , we need to acquire lock for each bucket! 123456789101112131415161718192021static void put(int key, int value)&#123; int i = key % NBUCKET; pthread_mutex_lock(&amp;lock[i]); // is the key already present? struct entry *e = 0; for (e = table[i]; e != 0; e = e-&gt;next) &#123; if (e-&gt;key == key) break; &#125; if(e)&#123; // update the existing key. e-&gt;value = value; &#125; else &#123; // the new is new. insert(key, value, &amp;table[i], table[i]); &#125; pthread_mutex_unlock(&amp;lock[i]); &#125; BarriersWe need all threads reach the barrier , we go the next stage. So we need to sleep a thread when it reaches. When all threads reach the barrier , clear the cnt 、 increase the round and wakeup other sleep thread! 1234567891011121314151617181920static void barrier()&#123; // YOUR CODE HERE // // Block until all threads have called barrier() and // then increment bstate.round. // pthread_mutex_lock(&amp;bstate.barrier_mutex); bstate.nthread++; if(bstate.nthread==nthread)&#123; bstate.round++; bstate.nthread = 0; pthread_cond_broadcast(&amp;bstate.barrier_cond); &#125;else&#123; pthread_cond_wait(&amp;bstate.barrier_cond, &amp;bstate.barrier_mutex); &#125; pthread_mutex_unlock(&amp;bstate.barrier_mutex); &#125; LinkThread Lab","categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"}]},{"title":"6.S081 Cow Lab","slug":"CowLab","date":"2020-11-16T07:20:14.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/11/16/CowLab/","link":"","permalink":"https://walkerzf.github.io/2020/11/16/CowLab/","excerpt":"","text":"Cow LabVirtual memory provides a level of indirection: the kernel can intercept memory references by marking PTEs invalid or read-only, leading to page faults， and can change what addresses mean by modifying PTEs. There is a saying in computer systems that any systems problem can be solved with a level of indirection. The lazy allocation lab provided one example which is talked about in the last lab. This lab explores another example: copy-on write fork. Fork’s ProblemThe fork() system call in xv6 copies all of the parent process’s user-space memory into the child. If the parent is large, copying can take a long time. Worse, the work is often largely wasted; for example, a fork() followed by exec() in the child will cause the child to discard the copied memory, probably without ever using most of it. On the other hand, if both parent and child use a page, and one or both writes it, a copy is truly needed. ImplementationThe goal of copy-on-write (COW) fork() is to defer allocating and copying physical memory pages for the child until the copies are actually needed, if ever. Cow fork will creates just a page table for the child , with PTEs for user memory pointing to the parent’s pa. Cow fork will marks all the user PTEs in both parent and child as not writable. When either process wants to write any of these unwritable pages, will triggle a page fault .The kernel trap will handle this fault , allocates a page of physical memory for the page fault,copies the original page into the new page, and modifies the relevant PTE in the faulting process to refer to the new page, this time with the PTE marked writeable. The original pa will be not changed. uvmcopy we will not allocate new pages , we increase the refcnt for the pa. Uvmcopy not allocate the new pa12345678910111213141516171819202122232425262728293031323334int uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)&#123; pte_t *pte; uint64 pa, i; uint flags; for (i = 0; i &lt; sz; i += PGSIZE) &#123; if ((pte = walk(old, i, 0)) == 0) panic(\"uvmcopy: pte should exist\"); if ((*pte &amp; PTE_V) == 0) panic(\"uvmcopy: page not present\"); //fix the permission bits pa = PTE2PA(*pte); *pte &amp;= ~PTE_W; flags = PTE_FLAGS(*pte); //not allocated // if((mem = kalloc()) == 0) // goto err; // memmove(mem, (char*)pa, PGSIZE); //increase refcnt increse(pa); //map the va to the same pa using flags if (mappages(new, i, PGSIZE, (uint64)pa, flags) != 0) &#123; goto err; &#125; &#125; return 0;err: uvmunmap(new, 0, i / PGSIZE, 1); return -1;&#125; Kalloc Kfree increase cntkalloc , we maintain the refcnt for every physical page .In the initialization , the refcnt will be writedto 1,because in the freerange ,we call kfree which decreases the refcnt for every pa. 1234567891011int refcnt[PHYSTOP / PGSIZE];void freerange(void *pa_start, void *pa_end)&#123; char *p; p = (char *)PGROUNDUP((uint64)pa_start); for (; p + PGSIZE &lt;= (char *)pa_end; p += PGSIZE) &#123; refcnt[(uint64)p / PGSIZE] = 1; kfree(p); &#125;&#125; increase refcnt and kfree is a combination , which is increase the refcnt of the pa , the other is decrease the refcnt of the pa .In the case when the refcnt of the pa down to zero , we really free the pa! 123456789101112131415161718192021222324252627282930313233343536373839void increse(uint64 pa)&#123; //acquire the lock acquire(&amp;kmem.lock); int pn = pa / PGSIZE; if(pa&gt;PHYSTOP || refcnt[pn]&lt;1)&#123; panic(\"increase ref cnt\"); &#125; refcnt[pn]++; release(&amp;kmem.lock);&#125;void kfree(void *pa)&#123; struct run *r; r = (struct run *)pa; if (((uint64)pa % PGSIZE) != 0 || (char *)pa &lt; end || (uint64)pa &gt;= PHYSTOP) panic(\"kfree\"); //when we free the page decraese the refcnt of the pa //we need to acquire the lock //and get the really current cnt for the current fucntion acquire(&amp;kmem.lock); int pn = (uint64)r / PGSIZE; if (refcnt[pn] &lt; 1) panic(\"kfree panic\"); refcnt[pn] -= 1; int tmp = refcnt[pn]; release(&amp;kmem.lock); if (tmp &gt;0) return; // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); acquire(&amp;kmem.lock); r-&gt;next = kmem.freelist; kmem.freelist = r; release(&amp;kmem.lock);&#125; kalloc function will allocate a pa , if the pa ref cnt is not valid , panic. 123456789101112131415161718192021222324void *kalloc(void)&#123; struct run *r; acquire(&amp;kmem.lock); r = kmem.freelist; if (r) &#123; int pn = (uint64)r / PGSIZE; if(refcnt[pn]!=0)&#123; panic(\"refcnt kalloc\"); &#125; refcnt[pn] = 1; kmem.freelist = r-&gt;next; &#125; release(&amp;kmem.lock); if (r) memset((char *)r, 5, PGSIZE); // fill with junk return (void *)r;&#125; Handle function in TrapThe r_scause of page fault is 15 or 13. In usertrap , we have cowfault. 1234567if (r_scause() == 15) &#123; if ((cowfault(p-&gt;pagetable, r_stval()) )&lt; 0) &#123; p-&gt;killed = 1; &#125; &#125; cowfault function handle the invalid va more than MAXVA not in the page table not set user bit or valid bit allocate a new pa , copy the original content to the new pa , unmap and map for this pte entry! or we cook up the ptestraightly 123456789101112131415161718192021int cowfault(pagetable_t pagetable, uint64 va)&#123; if (va &gt;= MAXVA) return -1; pte_t *pte = walk(pagetable, va, 0); if (pte == 0) return -1; if ((*pte &amp; PTE_U) == 0 || (*pte &amp; PTE_V) == 0) return -1; uint64 pa1 = PTE2PA(*pte); uint64 pa2 = (uint64)kalloc(); if (pa2 == 0)&#123; //panic(\"cow panic kalloc\"); return -1; &#125; memmove((void *)pa2, (void *)pa1, PGSIZE); *pte = PA2PTE(pa2) | PTE_U | PTE_V | PTE_W | PTE_X|PTE_R; kfree((void *)pa1); return 0;&#125; One more thing ,according to the hint : Modify copyout() to use the same scheme as page faults when it encounters a COW page. 123456va0 = PGROUNDDOWN(dstva);if (va0 &gt; MAXVA) return -1; if(cowfault(pagetable,va0)&lt;0)&#123; return -1;&#125; .The course lab site :MIT 6.S081 cow Lab","categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"}]},{"title":"6.S081 Lazy Lab","slug":"LazyLab","date":"2020-11-13T12:10:14.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/11/13/LazyLab/","link":"","permalink":"https://walkerzf.github.io/2020/11/13/LazyLab/","excerpt":"","text":"Lazy Lab One of the many neat tricks an O/S can play with page table hardware is lazy allocation of user-space heap memory. Xv6 applications ask the kernel for heap memory using the sbrk() system call. In the kernel we’ve given you, sbrk() allocates physical memory and maps it into the process’s virtual address space. It can take a long time for a kernel to allocate and map memory for a large request. Consider, for example, that a gigabyte consists of 262,144 4096-byte pages; that’s a huge number of allocations even if each is individually cheap. In addition, some programs allocate more memory than they actually use (e.g., to implement sparse arrays), or allocate memory well in advance of use. To allow sbrk() to complete more quickly in these cases, sophisticated kernels allocate user memory lazily. That is, sbrk() doesn’t allocate physical memory, but just remembers which user addresses are allocated and marks those addresses as invalid in the user page table. When the process first tries to use any given page of lazily-allocated memory, the CPU generates a page fault, which the kernel handles by allocating physical memory, zeroing it, and mapping it. You’ll add this lazy allocation feature to xv6 in this lab. Eliminate allocation from sbrk() for the system call sbrl the positive argument , we simply increase the size of the process ,which means grows the address space ,but mark the addresses not valid in the page table , the negative argument , we directly use the function growproc ,which actually calls uvmunmap 12345678910111213141516171819202122232425uint64sys_sbrk(void)&#123; int addr; int n; if (argint(0, &amp;n) &lt; 0) return -1; addr = myproc()-&gt;sz; if(myproc()-&gt;originalsz==-1)&#123; myproc()-&gt;originalsz = addr; &#125; if (n &gt; 0) &#123; myproc()-&gt;sz+=n; &#125; else if (n &lt; 0)&#123; if(growproc(n)&lt;0) return -1; &#125; // if(growproc(n) &lt; 0) // return -1; return addr;&#125; Lazy allocationOn a page fault on these not allocated address , the kernel allocates new pa and map into the page table. 12345678910111213141516171819202122232425262728else if (r_scause() == 15 || r_scause() == 13) &#123; uint64 va = r_stval(); if (va &gt;= p-&gt;sz) &#123; p-&gt;killed = 1; &#125; else if (va&lt;p-&gt;originalsz-PGSIZE) &#123; p-&gt;killed = 1; &#125; else &#123; //printf(\"page fault %p\\n\",va); char *mem; va = PGROUNDDOWN(va); mem = kalloc(); if (mem == 0) &#123; p-&gt;killed = 1; &#125; else &#123; memset(mem, 0, PGSIZE); mappages(p-&gt;pagetable, va, PGSIZE, (uint64)mem, PTE_W | PTE_X | PTE_R | PTE_U); &#125; &#125; &#125; Lazytests and UsertestsAccording to the hints! Handle negative sbrk() arguments. Kill a process if it page-faults on a virtual memory address higher than any allocated with sbrk(). Handle the parent-to-child memory copy in fork() correctly. Handle the case in which a process passes a valid address from sbrk() to a system call such as read or write, but the memory for that address has not yet been allocated. Handle out-of-memory correctly: if kalloc() fails in the page fault handler, kill the current process. Handle faults on the invalid page below the user stack. The negative argument is a little tricky ,we directly call growproc higher va or lower va will be invalid , the higher va is simple to find ,the lower va is under the stack which are the guard page and text and data In fork actually in uvmcopy , for the not exist page and not valid mapping , we ignore ! For the system call read and write , will happen “ page fault ” in walkaddr ,but not go to the usertrap,we need to handle it in walkaddr 123456789101112131415161718192021222324252627282930313233343536373839uint64walkaddr(pagetable_t pagetable, uint64 va)&#123; pte_t *pte; uint64 pa; if (va &gt;= MAXVA) return 0; pte = walk(pagetable, va, 0); if (pte == 0||(*pte &amp; PTE_V) == 0) &#123; if (va &gt;=myproc()-&gt;sz||va&lt;myproc()-&gt;originalsz-PGSIZE) &#123; pte = 0; return 0; &#125; char *mem; va = PGROUNDDOWN(va); mem = kalloc(); if (mem == 0) &#123; pte = 0; return 0; &#125; else &#123; memset(mem, 0, PGSIZE); mappages(pagetable, va, PGSIZE, (uint64)mem, PTE_W | PTE_X | PTE_R | PTE_U); pte = walk(pagetable, va, 0); &#125; &#125; // if ((*pte &amp; PTE_V) == 0) // return 0; if ((*pte &amp; PTE_V) == 0||(*pte &amp; PTE_U) == 0) return 0; pa = PTE2PA(*pte); return pa;&#125; .The course lab site :MIT 6.S081 Lazy Lab","categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"}]},{"title":"6.S081 Traps Lab","slug":"TrapLab","date":"2020-10-28T12:00:00.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/10/28/TrapLab/","link":"","permalink":"https://walkerzf.github.io/2020/10/28/TrapLab/","excerpt":"","text":"Trap LabThis lab explores how system calls are implemented using traps. Part 1 AssemblyThis part is a warm-up exercise to let you know a little more about Risc-v Assemble. Part 2 BacktraceA helper function in kernel . BackTrace helps us to print a list of functions calls on the stack. According to the hints ,we do it step by step. Using the r-tp to get the frame pointer of the current stack frame . Note that the return address lives at a fixed offset (-8) from the frame pointer of a stack frame, and that the saved frame pointer lives at fixed offset (-16) from the frame pointer. The operation on the pointer. Xv6 allocates one page for each stack in the xv6 kernel at PAGE-aligned address. If the fp not satisfied the one PGSIZE , the fp will at the bottom of the call stack 1234567891011121314151617// lab4 part2// backtracevoid backtrace(void)&#123; uint64 * currentfp = (uint64 *)r_fp(); uint64 up ; uint64 down ; do &#123; printf(\"%p\\n\", *(currentfp-1)); currentfp = (uint64*)(*(currentfp-2)); up = PGROUNDUP((uint64)currentfp); down = PGROUNDDOWN((uint64)currentfp); &#125; while (up-down==PGSIZE); &#125; Part 3 AlarmIn this part , we want to add two system call to xv6 . Once in user code we invoke system call , The mode will convert from user mode - &gt; kernel mode .`` ecall-&gt;usertrap-&gt;usertrapret-&gt;sret, after exiting the kernel mode ,thepcwill jump to thep-&gt;tramframe-&gt;epcwhich saves thesepc. So we know when to callhandlerfunction (time interrupt) , afterinterrupt we need to jump thehandlerfunction ,which means we fix the value inp-&gt;tramframe-&gt;epc` . The function pointer aka the address of the function ,aka the value of epc. In user code , we invoke sigalarm. In this system call implementation, we need to save the interval and function pointer in proc structure , an return user code , the p-&gt;tramfram-&gt;epc will be the next of ecall. When we have a timer interrupt ,we need the epc be the function pointer , for resuming the interrupted user code . Because usually we return the interrupted user code, this time ,we need to jump tohandler function ,we need to reserve the p-&gt;tramframe-&gt;* and change the p-&gt;tramframe-&gt;epc be the function pointer . In handler function ,we invoke sigreturn system call. In this implementation , we restore the saved registers when interrupted ,and jump to the original p-&gt;tramframe-&gt;epc resume the user code . 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748if (which_dev == 2) &#123; p-&gt;pastedticks++; if ((p-&gt;pastedticks &gt; 0) &amp;&amp; (p-&gt;pastedticks == p-&gt;interval)) &#123; if (p-&gt;permisson == 1) &#123; p-&gt;permisson = 0; p-&gt;epc = p-&gt;trapframe-&gt;epc; p-&gt;ra = p-&gt;trapframe-&gt;ra; p-&gt;sp = p-&gt;trapframe-&gt;sp; p-&gt;gp = p-&gt;trapframe-&gt;gp; p-&gt;tp = p-&gt;trapframe-&gt;tp; p-&gt;t0 = p-&gt;trapframe-&gt;t0; p-&gt;t1 = p-&gt;trapframe-&gt;t1; p-&gt;t2 = p-&gt;trapframe-&gt;t2; p-&gt;s0 = p-&gt;trapframe-&gt;s0; p-&gt;s1 = p-&gt;trapframe-&gt;s1; p-&gt;a0 = p-&gt;trapframe-&gt;a0; p-&gt;a1 = p-&gt;trapframe-&gt;a1; p-&gt;a2 = p-&gt;trapframe-&gt;a2; p-&gt;a3 = p-&gt;trapframe-&gt;a3; p-&gt;a4 = p-&gt;trapframe-&gt;a4; p-&gt;a5 = p-&gt;trapframe-&gt;a5; p-&gt;a6 = p-&gt;trapframe-&gt;a6; p-&gt;a7 = p-&gt;trapframe-&gt;a7; p-&gt;s2 = p-&gt;trapframe-&gt;s2; p-&gt;s3 = p-&gt;trapframe-&gt;s3; p-&gt;s4 = p-&gt;trapframe-&gt;s4; p-&gt;s5 = p-&gt;trapframe-&gt;s5; p-&gt;s6 = p-&gt;trapframe-&gt;s6; p-&gt;s7 = p-&gt;trapframe-&gt;s7; p-&gt;s8 = p-&gt;trapframe-&gt;s8; p-&gt;s9 = p-&gt;trapframe-&gt;s9; p-&gt;s10 = p-&gt;trapframe-&gt;s10; p-&gt;s11 = p-&gt;trapframe-&gt;s11; p-&gt;t3 = p-&gt;trapframe-&gt;t3; p-&gt;t4 = p-&gt;trapframe-&gt;t4; p-&gt;t5 = p-&gt;trapframe-&gt;t5; p-&gt;t6 = p-&gt;trapframe-&gt;t6; p-&gt;trapframe-&gt;epc = p-&gt;handler; p-&gt;pastedticks = 0; &#125; &#125; yield(); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// added system calluint64sys_sigreturn(void)&#123; struct proc *p = myproc(); p-&gt;permisson = 1; p-&gt;trapframe-&gt;epc = p-&gt;epc; p-&gt;trapframe-&gt;ra = p-&gt;ra; p-&gt;trapframe-&gt;sp = p-&gt;sp; p-&gt;trapframe-&gt;gp = p-&gt;gp; p-&gt;trapframe-&gt;tp = p-&gt;tp; p-&gt;trapframe-&gt;t0 = p-&gt;t0; p-&gt;trapframe-&gt;t1 = p-&gt;t1; p-&gt;trapframe-&gt;t2 = p-&gt;t2; p-&gt;trapframe-&gt;s0 = p-&gt;s0; p-&gt;trapframe-&gt;s1 = p-&gt;s1; p-&gt;trapframe-&gt;a0 = p-&gt;a0; p-&gt;trapframe-&gt;a1 = p-&gt;a1; p-&gt;trapframe-&gt;a2 = p-&gt;a2; p-&gt;trapframe-&gt;a3 = p-&gt;a3; p-&gt;trapframe-&gt;a4 = p-&gt;a4; p-&gt;trapframe-&gt;a5 = p-&gt;a5; p-&gt;trapframe-&gt;a6 = p-&gt;a6; p-&gt;trapframe-&gt;a7 = p-&gt;a7; p-&gt;trapframe-&gt;s2 = p-&gt;s2; p-&gt;trapframe-&gt;s3 = p-&gt;s3; p-&gt;trapframe-&gt;s4 = p-&gt;s4; p-&gt;trapframe-&gt;s5 = p-&gt;s5; p-&gt;trapframe-&gt;s6 = p-&gt;s6; p-&gt;trapframe-&gt;s7 = p-&gt;s7; p-&gt;trapframe-&gt;s8 = p-&gt;s8; p-&gt;trapframe-&gt;s9 = p-&gt;s9; p-&gt;trapframe-&gt;s10 = p-&gt;s10; p-&gt;trapframe-&gt;s11 = p-&gt;s11; p-&gt;trapframe-&gt;t3 = p-&gt;t3; p-&gt;trapframe-&gt;t4 = p-&gt;t4; p-&gt;trapframe-&gt;t5 = p-&gt;t5; p-&gt;trapframe-&gt;t6 = p-&gt;t6; return 0;&#125;//added system calluint64sys_sigalarm(void)&#123; struct proc *p = myproc(); if (argint(0, &amp;(p-&gt;interval)) &lt; 0) return -1; if (argaddr(1, &amp;(p-&gt;handler)) &lt; 0) return -1; return 0;&#125;","categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"}]},{"title":"6.S081 Pgtbl Lab","slug":"PgtblLab","date":"2020-10-22T15:13:14.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/10/22/PgtblLab/","link":"","permalink":"https://walkerzf.github.io/2020/10/22/PgtblLab/","excerpt":"","text":"Pgtbl Lab In this lab , we will explore the user page tables and kernel page table ,and modify or create a process‘s kernel page table to help simplify the functions that copy data from user space into the kernel space. The lab have three parts. Part 1 is simpler relatively,we need to print the valid pte in three-level page table. Part 2 and 3 can be seen as one part .In part 2 ,we need to copy a process’s page table which is identical to kernel page table ,and in part 3 ,we need to add user mapping to the process’s kernel page table . Part 1 print a page table In this part ,we need to print the first process ‘ page table ,so we can see the figure 1 ,which is the use address space .The user address space have several parts : text,data ,guard page , stack,trampoline and trapframe . From the function freewalk .which is recursively free page-table pages ,we can find that we need to recursively print the page table. And we have three-level depth page table , so we need a variable to record the depth of the recursion in the helper function. 123456789101112131415161718// Recursively free page-table pages.// All leaf mappings must already have been removed.void freewalk(pagetable_t pagetable)&#123; // there are 2^9 = 512 PTEs in a page table. for (int i = 0; i &lt; 512; i++)&#123; pte_t pte = pagetable[i]; if ((pte &amp; PTE_V) &amp;&amp; (pte &amp; (PTE_R | PTE_W | PTE_X)) == 0)&#123; // this PTE points to a lower-level page table. uint64 child = PTE2PA(pte); freewalk((pagetable_t)child); pagetable[i] = 0; &#125; else if (pte &amp; PTE_V)&#123; panic(\"freewalk: leaf\"); &#125; &#125; kfree((void *)pagetable);&#125; We can have the function like these. 123456789101112131415161718192021222324//heplerfunction for vmprintvoid helpervmprint(pagetable_t pagetable, int level)&#123; if (level &gt; 2) return; for (int i = 0; i &lt; 512; i++)&#123; pte_t pte = pagetable[i]; if ((pte &amp; PTE_V))&#123; //this pte pointer to a lower-level page table uint64 child = PTE2PA(pte); for (int j = 0; j &lt;= level; j++)&#123; printf(\"..\"); if (j != level) printf(\" \"); &#125; printf(\"%d: pte %p pa %p\\n\", i, pte, child); helpervmprint((pagetable_t)child, level + 1); &#125; &#125;&#125;//function to help print the contents of a page tablevoid vmprint(pagetable_t pagetable)&#123; printf(\"page table %p\\n\", pagetable); helpervmprint(pagetable, 0);&#125; We can get the output like this. In the top-level page table ,we have two entry. The first entry corresponding 1GB address. In the bottom page table ,we have three entries ,corresponding the text and data ,guard page and stack. The second entry in top-level page table , corresponding the trampoline and tramframe . We have two interesting points. The reason about the text and data are mapped together not respectively only for simplicity. The trampoline and tramframe are mapped highest in va , but in page table ,they are in entry 255,not in 511,because although the riscv uses 39-bits,it actually uses 38 bits ( because if we use the 39th bit ,the 40th 41th 42th ..etc should be set All for simplicity! But still support for the future!) , so in the top-level page table ,we only have 8 bits, the highest bit is 255. 12345678910page table 0x0000000087f6e000..0: pte 0x0000000021fda801 pa 0x0000000087f6a000.. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000.. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000.. .. ..1: pte 0x0000000021fda00f pa 0x0000000087f68000.. .. ..2: pte 0x0000000021fd9c1f pa 0x0000000087f67000..255: pte 0x0000000021fdb401 pa 0x0000000087f6d000.. ..511: pte 0x0000000021fdb001 pa 0x0000000087f6c000.. .. ..510: pte 0x0000000021fdd807 pa 0x0000000087f76000.. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000 We actually can print the PTE_FLAG for each valid pte. Part 2 A kernel page table per process The lab is vert time-consuming ,because we are doing kernel programming which is difficult to track the bug and easy to make error. The points we should pay attention to : The xv6 code is specialized for kernel page table the kernel page table init kvminit happens in pricinit and virto_disc. the memory free-up In part 3 , we will add user mapping in process’s kernel page table to allow the kernel to dereference the user pointer. This scheme rely on the user virtual memory range not overlapping the range of the va that the kernel address uses for its own instructions and data . Xv6 uses virtual addresses that start at zero for user address spaces, and luckily the kernel’s memory starts at higher addresses. However, this scheme does limit the maximum size of a user process to be less than the kernel’s lowest virtual address. After the kernel has booted, that address is 0xC000000 in xv6, the address of the PLIC registers .You’ll need to modify xv6 to prevent user processes from growing larger than the PLIC address. Through the calculating , thekernel base is in entry 2 .And the PLIC is in entry zero ,anything above the PLIC.So any user mapping below the PLIC will be added into process’s kernel page table .And anything above that will be identical to the kernel page table. So the entry 1-511 we can share the same page table with the kernel page table . The entry zero should be unique in process’s kernel page table. This is called share solution. We could have the naive copy solution , when we switch in process , we copy the ,when we switch out ,we free up the page table . The init of process kernel page table12345678910111213141516171819202122232425262728//share the 1-511 entry and map the entry zero for process 's kernel page table init// helper function void kvmmapkern(pagetable_t pagetable, uint64 va, uint64 pa, uint64 sz, int perm)&#123; if (mappages(pagetable, va, sz, pa, perm) != 0) panic(\"kvmmap\");&#125;// according to the Q&amp;A Lecture 7pagetable_t kvmcreate()&#123; pagetable_t p = uvmcreate(); int i; // we share the 1-511 entry for (i = 1; i &lt; 512; i++) &#123; p[i] = kernel_pagetable[i]; &#125; //we map the entry 0 and indentical to the kernel page table, add explicitly //we need a helper function because in kvminit function we do not //have an argument pagetable kvmmapkern(p, UART0, UART0, PGSIZE, PTE_R | PTE_W); kvmmapkern(p, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W); kvmmapkern(p, CLINT, CLINT, 0x10000, PTE_R | PTE_W); kvmmapkern(p, PLIC, PLIC, 0x400000, PTE_R | PTE_W); return p;&#125; The clean of process kernel page tableWhen we free the process’s kernel page table ,because entry 1-511 we share the same thing with the kernel page table ,so we do not need to free that memory . So we do free the lower level page table corresponding the entry zero. We can get medium level page table through the pagetable[0] , and free any valid pte and corresponding bottom level page table . 123456789101112131415161718192021222324//according to the Q&amp;A Lecture 7//a specialize kvmfree to match kvmcreate//because we share the 1-511 ,only entry to consider is entry 0//thus ,we only have one mid-level pagetable and possibly 512 bottom-level//we never have free the PA which is pointed by the bottom-level pte//because non were allocated by kvmcreatevoid kvmfree(pagetable_t pagetable, uint64 sz)&#123; pte_t pte = pagetable[0]; pagetable_t level1 = (pagetable_t)PTE2PA(pte); for (int i = 0; i &lt; 512; i++) &#123; pte_t p = level1[i]; if (p &amp; PTE_V) &#123; uint64 level2 = PTE2PA(p); kfree((void *) level2); level1[i] =0; &#125; &#125; kfree((void *)level1); kfree((void *)pagetable);&#125; According to the hints in part 2 ,we need to fix the scheduler() to load the process’s kernel page table when process is running ,when the no process is running ,the scheduler() will use the kernel page table. 1234567891011121314151617&#123; // Switch to chosen process. It is the process's job // to release its lock and then reacquire it // before jumping back to us. p-&gt;state = RUNNING; c-&gt;proc = p; w_satp(MAKE_SATP(p-&gt;kernelpgtbl)); sfence_vma(); swtch(&amp;c-&gt;context, &amp;p-&gt;context); // Process is done running for now. // It should have changed its p-&gt;state before coming back. c-&gt;proc = 0; w_satp(MAKE_SATP(kernel_pagetable)); sfence_vma(); found = 1; &#125; Part 3 Add user mappingTask: Simplify copyin/copyinstr Now for per process ,we have two page table: one is user page table and another is a copy for kernel page table . We want to help the simply copyin , when the kernel do not have user mapping ,the kernel needs to translate the va =&gt; pa in software .Your task is to add user mapping to the process’s kernel page table so that the kernel can dereference the user pointers directly. Advantages: Performance. When we need to move big bytes which can go out of PGSIZE , we need to walkaddr the va ,and move the pa .But when we have the correct user mapping ,we can using the page table. We can manipulate the user data freely .Eg . when we need to fix a file in a data structure ,we may need copy in and copy out 123456789101112131415161718192021222324252627282930313233343536//according to Q&amp;A lecture 7//copy ptes from the user pgtbl to process kernel pgtblvoid kvmmapuser(int pid, pagetable_t kpagetable, pagetable_t upagetable, uint64 newsz, uint64 oldsz)&#123; uint64 va; pte_t *upte; pte_t *kpte; if (newsz &gt; PLIC) panic(\"kvmmapuser:newsz too large\"); for (va = oldsz; va &lt; newsz; va += PGSIZE) &#123; upte = walk(upagetable, va, 0); //debug if (upte == 0) &#123; printf(\"kvmmapuser :0x%x 0x%x\\n\", va, newsz); panic(\"kvmmapuser:not upte\"); &#125; if ((*upte &amp; PTE_V) == 0) &#123; printf(\"kvmmapuser : no valid pte 0x%x 0x%x\\n\", va, newsz); panic(\"kvmmapuser:not valid upte\"); &#125; kpte = walk(kpagetable, va, 1); if (kpte == 0) panic(\"kvmmapuser:no kpte\"); *kpte = *upte; *kpte &amp;= ~(PTE_U | PTE_W | PTE_X); &#125; // if newsz &lt; oldsz clear ptes , not necessary //check p-&gt;sz will not use thess ptes for (va = newsz; va &lt; oldsz; va += PGSIZE)&#123; kpte = walk(kpagetable, va, 1); *kpte &amp;= ~PTE_V; &#125;&#125; When we add the kvmmapuser in fork , the third argument should be new process’s page table , because when we fork many times, the old process may exit ,the old process ‘s page table may be cleaned up. The course lab site :MIT 6.S081 pgtbl","categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"}]},{"title":"Introduction","slug":"hello-world","date":"2020-10-15T12:14:25.000Z","updated":"2020-11-22T06:41:23.252Z","comments":true,"path":"2020/10/15/hello-world/","link":"","permalink":"https://walkerzf.github.io/2020/10/15/hello-world/","excerpt":"","text":"Welcome to Zat’s Blog.My name is Zhou Fang. Education 2015/9~2019/6 | BeiHang University | Electrical Engineering | Bachelor 2019/9~ | ZheJiang University | Electrical Engineering | Master ExperienceLink [Github][https://github.com/walkerzf]","categories":[{"name":"intro","slug":"intro","permalink":"https://walkerzf.github.io/categories/intro/"}],"tags":[{"name":"intro","slug":"intro","permalink":"https://walkerzf.github.io/tags/intro/"}]}],"categories":[{"name":"6.S081","slug":"6-S081","permalink":"https://walkerzf.github.io/categories/6-S081/"},{"name":"intro","slug":"intro","permalink":"https://walkerzf.github.io/categories/intro/"}],"tags":[{"name":"Lab","slug":"Lab","permalink":"https://walkerzf.github.io/tags/Lab/"},{"name":"intro","slug":"intro","permalink":"https://walkerzf.github.io/tags/intro/"}]}